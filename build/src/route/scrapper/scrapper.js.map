{"version":3,"sources":["../../../../server/src/route/scrapper/scrapper.js"],"names":["scrapeRoute","post","req","res","url","decodeURIComponent","query","search","request","error","response","body","title","isbn","description","coverages","coverage","data","$","cheerio","load","content","Array","from","forEach","journal","index","children","next","find","each","i","cite","name","push","link","firstChild","attribs","text","send","console","log"],"mappings":";;;;;;AAAA;;AAGA,IAAIA,cAAc,sBAAlB;;AAGAA,YAAYC,IAAZ,CAAiB,SAAjB,EAA4B,UAACC,GAAD,EAAMC,GAAN,EAAc;AACxC;AACA,MAAIC,MAAMC,mBAAmBH,IAAII,KAAJ,CAAUC,MAA7B,CAAV;AACA;;AAEAC,UAAQJ,GAAR,EAAa,UAAUK,KAAV,EAAiBC,QAAjB,EAA2BC,IAA3B,EAAiC;AAC5C,QAAIC,cAAJ;AAAA,QAAWC,aAAX;AAAA,QAAiBC,oBAAjB;AAAA,QAA8BC,kBAA9B;AAAA,QAAyCC,iBAAzC;AACAD,gBAAY,EAAZ;AACAC,eAAW,EAAX;AACA,QAAIC,OAAO,EAAX;;AAEA,QAAI,CAACR,KAAL,EAAY;AACV,UAAIS,IAAIC,QAAQC,IAAR,CAAaT,IAAb,CAAR;;AAEA,UAAIU,UAAUC,MAAMC,IAAN,CAAWL,EAAE,2BAAF,CAAX,CAAd;AACAG,cAAQG,OAAR,CAAgB,UAACC,OAAD,EAAUC,KAAV,EAAoB;AAClCd,gBAAQa,QAAQE,QAAR,CAAiB,CAAjB,EAAoBA,QAApB,CAA6B,CAA7B,EAAgCV,IAAxC;AACAJ,eAAOY,QAAQE,QAAR,CAAiB,CAAjB,EAAoBV,IAA3B;AACAH,sBAAcW,QAAQE,QAAR,CAAiB,CAAjB,EAAoBC,IAApB,CAAyBA,IAAzB,CAA8BX,IAA5C;AACA;AACAC,UAAEO,OAAF,EAAWI,IAAX,CAAgB,UAAhB,EAA4BC,IAA5B,CAAiC,UAACC,CAAD,EAAIC,IAAJ,EAAa;AAC5ChB,qBAAW,EAAX;AACAgB,eAAKL,QAAL,CAAcH,OAAd,CAAsB,gBAAQ;AAC5B,gBAAIS,KAAKA,IAAL,KAAc,IAAlB,EAAwB;AACtB;AACAjB,uBAASkB,IAAT,CAAc;AACZC,sBAAOF,KAAKG,UAAL,CAAgBC,OADX;AAEZC,sBAAML,KAAKG,UAAL,CAAgBT,QAAhB,CAAyB,CAAzB,EAA4BV;AAFtB,eAAd;AAMD;AACF,WAVD;AAYD,SAdD;AAeA;AACAA,aAAKiB,IAAL,CAAU;AACRtB,sBADQ;AAERC,oBAFQ;AAGRC,kCAHQ;AAIRE;AAJQ,SAAV;AAOD,OA5BD;;AA8BAb,UAAIoC,IAAJ,CAAStB,IAAT;AACD,KAnCD,MAmCO;AACLuB,cAAQC,GAAR,CAAY,iCAAiChC,KAA7C;AACD;AACF,GA5CD;AA6CD,CAlDD;;kBAqDeT,W","file":"scrapper.js","sourcesContent":["import { Router } from 'express';\n\n\nlet scrapeRoute = Router();\n \n\nscrapeRoute.post('/search', (req, res) => {\n  // console.log(req.query)\n  let url = decodeURIComponent(req.query.search);\n  // console.log(url)\n\n  request(url, function (error, response, body) {\n    let title, isbn, description, coverages, coverage;\n    coverages = [];\n    coverage = [];\n    let data = [];\n\n    if (!error) {\n      let $ = cheerio.load(body)\n\n      let content = Array.from($('#results > form > ul > li'));\n      content.forEach((journal, index) => {\n        title = journal.children[0].children[0].data;\n        isbn = journal.children[1].data;\n        description = journal.children[1].next.next.data;\n        // \n        $(journal).find(\"div > ul\").each((i, cite) => {\n          coverage = [];\n          cite.children.forEach(name => {\n            if (name.name === 'li') {\n              // console.log(name.firstChild.attribs)\n              coverage.push({\n                link: (name.firstChild.attribs),\n                text: name.firstChild.children[0].data\n              });\n\n\n            }\n          });\n\n        })\n        //  coverage.push(coverages);\n        data.push({\n          title,\n          isbn,\n          description,\n          coverage\n        });\n\n      })\n\n      res.send(data);\n    } else {\n      console.log(\"Weâ€™ve encountered an error: \" + error);\n    }\n  });\n});\n\n\nexport default scrapeRoute;"]}